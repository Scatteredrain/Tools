{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huqiang/anaconda3/envs/SLTnet/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIF generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bboxes(image, bboxes, line_thickness=None):\n",
    "    # Plots one bounding box on image img\n",
    "    tl = line_thickness or round(\n",
    "        0.002 * (image.shape[0] + image.shape[1]) / 2) + 1  # line/font thickness\n",
    "    for (x1, y1, x2, y2, cls_id, pos_id) in bboxes:\n",
    "        if cls_id in ['person']:\n",
    "            color = (0, 0, 255)\n",
    "        else:\n",
    "            color = (0, 255, 0)\n",
    "        c1, c2 = (x1, y1), (x2, y2)\n",
    "        cv2.rectangle(image, c1, c2, (255,255,255), thickness=1, lineType=cv2.LINE_AA)\n",
    "        tf = max(tl - 1, 1)  # font thickness\n",
    "        t_size = cv2.getTextSize(cls_id, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "        cv2.rectangle(image, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(image, '{} ID-{}'.format(cls_id, pos_id), (c1[0], c1[1] - 2), 0, tl / 3,\n",
    "                    [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "        \n",
    "        mask = np.zeros(image.shape)\n",
    "        mask[y1:y2,x1:x2,0] = 238\n",
    "        mask[y1:y2,x1:x2,1] = 130\n",
    "        mask[y1:y2,x1:x2,2] = 238\n",
    "        \n",
    "        # contours,_ = cv2.findContours(np.uint8(mask),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # cv2.drawContours(image,contours,-1,(238,130,238),1)\n",
    "        image = cv2.add(image,np.uint8(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(img, mask=None):\n",
    "    if mask is None:\n",
    "        return cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        mask_edge, _= cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        alpha = 0.6\n",
    "        purple_mask = np.zeros_like(img)# purple mask[mask==255]=(226.43,138)\n",
    "        purple_mask[mask==255]=(225,61,72)# overlay = img.copy()\n",
    "        output =cv2.addWeighted(img, alpha, purple_mask,1- alpha, 0)\n",
    "        cv2.drawContours(output,mask_edge,-1,(255,255,255),thickness=2)#绘制预测mask的边界\n",
    "        # plt.imshow(output)\n",
    "        \n",
    "        return cv2.cvtColor(output,cv2.COLOR_BGR2RGB)\n",
    "    # cv2.imwrite('merge.png', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_root = '/memory/yizhenyu/dataset/SUN/data/SUN-SEG/TestHardDataset/Unseen/Frame/'\n",
    "models = ['SALI','MAST','PNS+','PNS-Net','23D']\n",
    "pred_root = ['/data/yizhenyu/project/video-polyp-seg/SLT-Net_align_Memory/res/cas_long2short/Net_epoch_4_best/SUN-SEG/TestHardDataset/Unseen/'\n",
    ",           '/data/yizhenyu/datasets/pvt_MAST/TestHardDataset/Unseen/'\n",
    ",           '/data/yizhenyu/datasets/Benchmark/2022-MIR-PNS+/TestHardDataset/Unseen/'\n",
    ",           '/data/yizhenyu/datasets/Benchmark/2021-MICCAI-PNSNet/TestHardDataset/Unseen/'\n",
    ",           '/data/yizhenyu/datasets/Benchmark/2020-MICCAI-23DCNN/TestHardDataset/Unseen/'\n",
    "]\n",
    "\n",
    "image_sequence = []\n",
    "gt_sequence = []\n",
    "pred_sequence = [ [] for i in range(len(pred_root))]\n",
    "\n",
    "############ \n",
    "\n",
    "# select, ranges = 'case29_1/case_M_20181018093806_0U62363101890605_1_007_002-1_a10_ayy_image', range(34,95)\n",
    "# select, ranges = 'case32_4/case_M_20181019101517_0U62367101935917_1_003_001-1_a15_ayy_image', range(50,111)\n",
    "select, select_ranges = 'case68_4/case_M_20181214095357_0U62368121473456_1_006_003-1_a18_ayy_image', range(33,94)\n",
    "\n",
    "############\n",
    "\n",
    "\n",
    "for j in select_ranges:\n",
    "    sample = select + f'{\"%04d\" % j}' + '.jpg'\n",
    "    \n",
    "    img_path = img_root + sample\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    gt_path = img_path.replace('Frame','GT').replace('.jpg','.png')\n",
    "    gt = cv2.imread(gt_path,cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    for idx in range(len(models)): \n",
    "        mask_path = pred_root[idx] + sample.replace('.jpg','.png')\n",
    "        pred = cv2.imread(mask_path,cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if not gt.shape == pred.shape:\n",
    "            pred = cv2.resize(pred, (gt.shape[1], gt.shape[0]))\n",
    "        pred = np.uint8(pred > 128)*255\n",
    "        pred_sequence[idx].append(plot(img,pred))\n",
    "\n",
    "\n",
    "    image_sequence.append(plot(img))\n",
    "    gt_sequence.append(plot(img,gt))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimsave(select.split('/')[0]+'/'+select.split('/')[1].split('_')[-3]+'_'+'23D'+'_pred.gif', pred_sequence[idx], duration=0.1, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "The directory '/data/yizhenyu/project/tools/keshihua/case68_4/a18_2' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m imageio\u001b[38;5;241m.\u001b[39mmimsave(select\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mselect\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_gt.gif\u001b[39m\u001b[38;5;124m'\u001b[39m,gt_sequence, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models):\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mimageio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmimsave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_pred.gif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_sequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SLTnet/lib/python3.8/site-packages/imageio/v2.py:494\u001b[0m, in \u001b[0;36mmimwrite\u001b[0;34m(uri, ims, format, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m imopen_args \u001b[38;5;241m=\u001b[39m decypher_format_arg(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    493\u001b[0m imopen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 494\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mimopen_args\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mwrite(ims, is_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/SLTnet/lib/python3.8/site-packages/imageio/core/imopen.py:113\u001b[0m, in \u001b[0;36mimopen\u001b[0;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     request\u001b[38;5;241m.\u001b[39mformat_hint \u001b[38;5;241m=\u001b[39m format_hint\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<bytes>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(uri, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m uri\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# fast-path based on plugin\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# (except in legacy mode)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/SLTnet/lib/python3.8/site-packages/imageio/core/request.py:247\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[0;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Request.Mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Parse what was given\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Set extension\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/SLTnet/lib/python3.8/site-packages/imageio/core/request.py:412\u001b[0m, in \u001b[0;36mRequest._parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    410\u001b[0m dn \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(fn)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(dn):\n\u001b[0;32m--> 412\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe directory \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m dn)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: The directory '/data/yizhenyu/project/tools/keshihua/case68_4/a18_2' does not exist"
     ]
    }
   ],
   "source": [
    "os.makedirs(select.split('/')[0],exist_ok=True)\n",
    "imageio.mimsave(select.split('/')[0]+'/'+select.split('/')[1].split('_')[-3]+ '_img.gif', image_sequence, duration=0.1, loop=0)\n",
    "imageio.mimsave(select.split('/')[0]+'/'+select.split('/')[1].split('_')[-3]+'_gt.gif',gt_sequence, duration=0.1, loop=0)\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    imageio.mimsave(select.split('/')[0]+'/'+select.split('/')[1].split('_')[-3]+'_'+model+'_pred.gif', pred_sequence[idx], duration=0.1, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'case68_4/case_M_20181214095357_0U62368121473456_1_006_003-1_a18_ayy_image0001.png'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = 'case68_4/case_M_20181214095357_0U62368121473456_1_006_003-1_a18_ayy_image'\n",
    "i=1\n",
    "select + f'{\"%04d\" % i}' + '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file demo.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import moviepy.editor as mp\n",
    "\n",
    "# 读取 MP4 视频文件\n",
    "clip = VideoFileClip(\"demo.mp4\")\n",
    "\n",
    "# 将视频转换为 GIF，并设置循环次数为 0，表示无限循环播放\n",
    "clip.write_gif(\"demo.gif\", fps=30, loop=0)\n",
    "\n",
    "# # 在此处将 gif 转换为 mp4 文件\n",
    "# clip.write_videofile(\"output.mp4\", fps=10, codec='libx264', audio_codec='aac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = imageio.get_reader('demo.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<imageio.plugins.ffmpeg.FfmpegFormat.Reader at 0x7f1f94637610>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = reader.get_meta_data()['fps']\n",
    "with imageio.get_writer('output2.gif', duration=0.1,loop=0) as writer:\n",
    "    for frame in reader:\n",
    "        writer.append_data(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change weights-key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huqiang/anaconda3/envs/SLTnet/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_dir = '../../video-polyp-seg/LSI-Net/snapshot/model_changed.pth'\n",
    "dict = torch.load(model_dir,map_location=lambda storage, loc: storage.cuda(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list(dict.keys()):\n",
    "    if key.startswith('ls_fusion_conv'):\n",
    "        del dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_key = [\"nlnet.nl_layer1.nonlocals.0.g.0.weight\",  \"nlnet.nl_layer1.nonlocals.0.g.0.bias\", \n",
    "           \"nlnet.nl_layer1.nonlocals.0.W.weight\", \"nlnet.nl_layer1.nonlocals.0.W.bias\", \n",
    "           \"nlnet.nl_layer1.out_conv.weight\", \"nlnet.nl_layer1.out_conv.bias\", \n",
    "\n",
    "           \"nlnet.nl_layer2.nonlocals.0.g.0.weight\", \"nlnet.nl_layer2.nonlocals.0.g.0.bias\", \n",
    "            \"nlnet.nl_layer2.nonlocals.0.W.weight\", \"nlnet.nl_layer2.nonlocals.0.W.bias\", \n",
    "            \"nlnet.nl_layer2.out_conv.weight\", \"nlnet.nl_layer2.out_conv.bias\", \n",
    "\n",
    "            \"nlnet.nl_layer3.nonlocals.0.g.0.weight\", \"nlnet.nl_layer3.nonlocals.0.g.0.bias\", \n",
    "            \"nlnet.nl_layer3.nonlocals.0.W.weight\", \"nlnet.nl_layer3.nonlocals.0.W.bias\", \n",
    "            \"nlnet.nl_layer3.out_conv.weight\", \"nlnet.nl_layer3.out_conv.bias\"]\n",
    "\n",
    "new_key = [\"nlnet.nl_layer1.g.0.weight\", \"nlnet.nl_layer1.g.0.bias\", \n",
    "           \"nlnet.nl_layer1.W.0.weight\", \"nlnet.nl_layer1.W.0.bias\", \n",
    "           \"nlnet.nl_layer1.residual_conv.weight\", \"nlnet.nl_layer1.residual_conv.bias\", \n",
    "        \n",
    "           \"nlnet.nl_layer2.g.0.weight\", \"nlnet.nl_layer2.g.0.bias\",          \n",
    "           \"nlnet.nl_layer2.W.0.weight\", \"nlnet.nl_layer2.W.0.bias\", \n",
    "           \"nlnet.nl_layer2.residual_conv.weight\", \"nlnet.nl_layer2.residual_conv.bias\", \n",
    "\n",
    "            \"nlnet.nl_layer3.g.0.weight\", \"nlnet.nl_layer3.g.0.bias\", \n",
    "            \"nlnet.nl_layer3.W.0.weight\", \"nlnet.nl_layer3.W.0.bias\", \n",
    "            \"nlnet.nl_layer3.residual_conv.weight\", \"nlnet.nl_layer3.residual_conv.bias\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_key = [\"nlnet.nl_layer1.W.0.weight\", \"nlnet.nl_layer1.W.0.bias\",\n",
    "            \"nlnet.nl_layer2.W.0.weight\", \"nlnet.nl_layer2.W.0.bias\", \n",
    "            \"nlnet.nl_layer3.W.0.weight\", \"nlnet.nl_layer3.W.0.bias\"]\n",
    "new_key = [\"nlnet.nl_layer1.W.weight\", \"nlnet.nl_layer1.W.bias\", \"nlnet.nl_layer2.W.weight\", \"nlnet.nl_layer2.W.bias\", \"nlnet.nl_layer3.W.weight\", \"nlnet.nl_layer3.W.bias\"]\n",
    "for i in range(len(old_key)):\n",
    "    new = new_key[i]\n",
    "    old = old_key[i]\n",
    "    dict[new] = dict.pop(old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(dict, '../../video-polyp-seg/LSI-Net/snapshot/model_changed.pth')\n",
    "#验证修改是否成功\n",
    "# changed_dict = torch.load('../../video-polyp-seg/LSI-Net/snapshot/model_changed.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate the size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 4719\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cases = 0\n",
    "frames = 0\n",
    "path = '/memory/yizhenyu/dataset/SUN/data/SUN-SEG/TestEasyDataset/Seen/Frame/'\n",
    "cases = len(list(os.listdir(path)))\n",
    "for case in os.listdir(path):\n",
    "    for file in os.listdir(path+case):\n",
    "        img = os.path.join(path,case,file)\n",
    "        if img.endswith('jpg'):\n",
    "            frames += 1\n",
    "        else:\n",
    "            print(img)\n",
    "\n",
    "print(cases,frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/memory/yizhenyu/dataset/SUN/data/SUN-SEG/TestEasyDataset/Unseen/Frame/case24_4/.DS_Store\n",
      "/memory/yizhenyu/dataset/SUN/data/SUN-SEG/TestEasyDataset/Unseen/Frame/case24_4/._.DS_Store\n",
      "86 12351\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cases = 0\n",
    "frames = 0\n",
    "path = '/memory/yizhenyu/dataset/SUN/data/SUN-SEG/TestEasyDataset/Unseen/Frame/'\n",
    "cases = len(list(os.listdir(path)))\n",
    "for case in os.listdir(path):\n",
    "    for file in os.listdir(path+case):\n",
    "        img = os.path.join(path,case,file)\n",
    "        if img.endswith('jpg'):\n",
    "            frames += 1\n",
    "        else:\n",
    "            print(img)\n",
    "print(cases,frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 3882\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cases = 0\n",
    "frames = 0\n",
    "path = '/memory/yizhenyu/dataset/SUN/data/SUN-SEG/TestHardDataset/Seen/Frame/'\n",
    "cases = len(list(os.listdir(path)))\n",
    "for case in os.listdir(path):\n",
    "    for file in os.listdir(path+case):\n",
    "        img = os.path.join(path,case,file)\n",
    "        if img.endswith('jpg'):\n",
    "            frames += 1\n",
    "        else:\n",
    "            print(img)\n",
    "print(cases,frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 8640\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cases = 0\n",
    "frames = 0\n",
    "path = '/memory/yizhenyu/dataset/SUN/data/SUN-SEG/TestHardDataset/Unseen/Frame/'\n",
    "cases = len(list(os.listdir(path)))\n",
    "for case in os.listdir(path):\n",
    "    for file in os.listdir(path+case):\n",
    "        img = os.path.join(path,case,file)\n",
    "        if img.endswith('jpg'):\n",
    "            frames += 1\n",
    "        else:\n",
    "            print(img)\n",
    "print(cases,frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLTnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
