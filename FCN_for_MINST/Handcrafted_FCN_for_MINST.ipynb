{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "from gzip import struct\n",
    "import gzip\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Test camera and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while(cap.isOpened()):\n",
    "    retval, frame = cap.read()\n",
    "    cv2.imshow('Live', frame)\n",
    "    if cv2.waitKey(5) >= 0:\n",
    "        image = frame\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(X,H,channel_sum=False):\n",
    "    h,w,c = X.shape\n",
    "    p,q = H.shape\n",
    "    if c!=3:\n",
    "        X = np.transpose(X,(2,0,1))\n",
    "        h,w,c = X.shape\n",
    "\n",
    "    output = np.zeros((h+p-1,w+q-1,c))\n",
    "\n",
    "    for channel in range(c):\n",
    "        output[:,:,channel] = convolve2d(X[:,:,channel],H)\n",
    "\n",
    "    if channel_sum:\n",
    "        output = np.sum(output,axis=-1)\n",
    "\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = np.array(\n",
    "    [\n",
    "        [-1,0,1],\n",
    "        [-1,0,1],\n",
    "        [-1,0,1]\n",
    "    ]\n",
    "    ,dtype='uint8'\n",
    ")\n",
    "\n",
    "out = filter(image,H,channel_sum=True)\n",
    "plt.imshow(np.uint8(out),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 1/16 * np.array(\n",
    "    [\n",
    "        [1,2,1],\n",
    "        [2,4,2],\n",
    "        [1,2,1]\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "out = filter(image,H)\n",
    "out = cv2.cvtColor(np.uint8(out),cv2.COLOR_RGB2BGR)\n",
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.MINIST Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "下载MNIST数据集脚本\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import wget\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(message)s\")\n",
    "\n",
    "\n",
    "def download_minst(save_dir: str = None) -> bool:\n",
    "    \"\"\"下载MNIST数据集\n",
    "    \"\"\"\n",
    "    save_dir = Path(save_dir)\n",
    "    train_set_imgs_addr = save_dir / \"train-images-idx3-ubyte.gz\"\n",
    "    train_set_labels_addr = save_dir / \"train-labels-idx1-ubyte.gz\"\n",
    "    test_set_imgs_addr = save_dir / \"t10k-images-idx3-ubyte.gz\"\n",
    "    test_set_labels_addr = save_dir / \"t10k-labels-idx1-ubyte.gz\"\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(train_set_imgs_addr):\n",
    "            logging.info(\"下载train-images-idx3-ubyte.gz\")\n",
    "            filename = wget.download(url=\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\", out=str(train_set_imgs_addr))\n",
    "            logging.info(\"\\tdone.\")\n",
    "        else:\n",
    "            logging.info(\"train-images-idx3-ubyte.gz已经存在.\")\n",
    "\n",
    "        if not os.path.exists(train_set_labels_addr):\n",
    "            logging.info(\"下载train-labels-idx1-ubyte.gz.\")\n",
    "            filename = wget.download(url=\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\", out=str(train_set_labels_addr))\n",
    "            logging.info(\"\\tdone.\")\n",
    "        else:\n",
    "            logging.info(\"train-labels-idx1-ubyte.gz已经存在.\")\n",
    "\n",
    "        if not os.path.exists(test_set_imgs_addr):\n",
    "            logging.info(\"下载t10k-images-idx3-ubyte.gz.\")\n",
    "            filename = wget.download(url=\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\", out=str(test_set_imgs_addr))\n",
    "            logging.info(\"\\tdone.\")\n",
    "        else:\n",
    "            logging.info(\"t10k-images-idx3-ubyte.gz已经存在.\")\n",
    "\n",
    "        if not os.path.exists(test_set_labels_addr):\n",
    "            logging.info(\"下载t10k-labels-idx1-ubyte.gz.\")\n",
    "            filename = wget.download(url=\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\", out=str(test_set_labels_addr))\n",
    "            logging.info(\"\\tdone.\")\n",
    "        else:\n",
    "            logging.info(\"t10k-labels-idx1-ubyte.gz已经存在.\")\n",
    "        \n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "download_minst(save_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_train(path, kind='train'): \n",
    "\n",
    "    labels_path = os.path.join(path,'%s-labels-idx1-ubyte.gz'% kind)\n",
    "    images_path = os.path.join(path,'%s-images-idx3-ubyte.gz'% kind)\n",
    "    #使用gzip打开文件\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "\t    #使用struct.unpack方法读取前两个数据，>代表高位在前，I代表32位整型。lbpath.read(8)表示一次从文件中读取8个字节\n",
    "\t    #这样读到的前两个数据分别是magic number和样本个数\n",
    "        magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "        #使用np.fromstring读取剩下的数据，lbpath.read()表示读取所有的数据\n",
    "        labels = np.frombuffer(lbpath.read(),dtype=np.uint8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "        images = np.frombuffer(imgpath.read(),dtype=np.uint8).reshape(len(labels), 784)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, labels_train = load_mnist_train('E:\\lecture\\zuoye\\Mine\\gcsj\\MNIST','train')\n",
    "images_val, labels_val = load_mnist_train('E:\\lecture\\zuoye\\Mine\\gcsj\\MNIST','t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu():\n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        # print('X:',X)\n",
    "        return np.where(X > 0, X, np.zeros_like(X))\n",
    "\n",
    "    def backward(self, grad_pre):\n",
    "        X = self.X\n",
    "        return (X > 0).astype(np.float32) * grad_pre\n",
    "\n",
    "\n",
    "# class Softmax():\n",
    "#     def __init__(self):\n",
    "#         self.X = None\n",
    "\n",
    "#     def forward(self, X):\n",
    "#         X_exp = np.exp(X)\n",
    "#         denominator = np.sum(X_exp, axis=1, keepdims=True)\n",
    "#         X = X_exp / (denominator + 1e-6)\n",
    "#         self.X_exp = X_exp\n",
    "#         return X\n",
    "\n",
    "#     def backward(self, grad_s):\n",
    "#         s = self.X_exp\n",
    "#         tmp = np.matmul(np.expand_dims(grad_s, axis=1), np.diag(s))\n",
    "#         tmp = np.squeeze(tmp, axis=1)\n",
    "#         grad_p = -tmp + grad_s * s\n",
    "#         return grad_p\n",
    "\n",
    "\n",
    "class Sigmoid():\n",
    "    def __init__(self):\n",
    "        self.X_sig = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = 1 / (1 + np.exp(-1*X))\n",
    "        self.X_sig = X\n",
    "        return X\n",
    "\n",
    "    def backward(self, grad_s):\n",
    "        s = self.X_sig\n",
    "        # print(grad_s.shape,s.shape)\n",
    "        grad_p = grad_s * s * (1-s)\n",
    "        return grad_p\n",
    "\n",
    "class LinearLayer():\n",
    "    def __init__(self, C_input, C_output=3):\n",
    "        self.C_input = C_input\n",
    "        self.C_output = C_output\n",
    "        self.X = None\n",
    "        self.W = np.random.normal(loc=0, scale=1, size=[C_output, C_input]) / np.sqrt((C_input) / 2)  # He 初始化，有效提高 Relu 网络的性能\n",
    "\n",
    "    def forward(self,X):\n",
    "        self.X = X   #[in,1]\n",
    "        return np.matmul(self.W,X)    #[out,in]@[in,1] -> [out,1]\n",
    "    \n",
    "    def backward(self,grad_pre,lr):\n",
    "        grad_here = np.matmul(self.W.T,grad_pre)  #[in,out]@[out,1] -> [in,1]\n",
    "        self.W -= lr*np.matmul(grad_pre,self.X.T)    #[out,1]@[1,in] -> [out,in]\n",
    "        return grad_here\n",
    "    \n",
    "        # print('grad_pre',grad_pre.shape) #1,1\n",
    "        # print('self.W.T',self.W.T.shape) #3,1\n",
    "        # print('self.X',self.X.shape)  #1,3\n",
    "class L2_loss():\n",
    "\n",
    "    def forward(self,P,Y):\n",
    "        en = P-Y # [1,1]\n",
    "        loss = (en@en.T)**2 / 2\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def backward(self,P,Y):\n",
    "        return P-Y\n",
    "\n",
    "class Fully_Connect_Network():\n",
    "    def __init__(self, C_input, C_output):\n",
    "        self.C_input = C_input\n",
    "        self.C_output = C_output\n",
    "\n",
    "        self.layer_in = LinearLayer(C_input,400)\n",
    "        self.layer_hidden_1 = LinearLayer(400,200)\n",
    "        self.layer_hidden_2 = LinearLayer(200,100)\n",
    "        self.layer_out = LinearLayer(100,C_output)\n",
    "\n",
    "        self.NonLinear_1 = Sigmoid()\n",
    "        self.NonLinear_2 = Sigmoid()\n",
    "        self.NonLinear_3 = Sigmoid()\n",
    "        self.NonLinear_out = Sigmoid()\n",
    "        self.loss = L2_loss()\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = self.layer_in.forward(X)\n",
    "        # print('1:',X.shape)\n",
    "        X = self.NonLinear_1.forward(X) \n",
    "\n",
    "        X = self.layer_hidden_1.forward(X)\n",
    "        # print('2:',X.shape)\n",
    "        X = self.NonLinear_2.forward(X)     \n",
    "\n",
    "        X = self.layer_hidden_2.forward(X)\n",
    "        # print('3:',X.shape)\n",
    "        X = self.NonLinear_3.forward(X)\n",
    "\n",
    "        X = self.layer_out.forward(X)\n",
    "        # print('4:',X.shape)\n",
    "        X = self.NonLinear_out.forward(X)\n",
    "        # print('Pred',X)\n",
    "        \n",
    "        return X\n",
    "        # X = self.NonLinear_out.forward(X)\n",
    "\n",
    "\n",
    "    def backward(self,P,Y,lr):\n",
    "        \n",
    "        loss = self.loss.forward(P,Y)\n",
    "        grad = self.loss.backward(P,Y)\n",
    "        # print('1:',grad.shape)\n",
    "        \n",
    "        grad = self.NonLinear_out.backward(grad)\n",
    "        grad = self.layer_out.backward(grad,lr)\n",
    "        # print('2:',grad.shape)\n",
    "        grad = self.NonLinear_3.backward(grad)\n",
    "        grad = self.layer_hidden_2.backward(grad,lr)\n",
    "        # print('3:',grad.shape)\n",
    "        grad = self.NonLinear_2.backward(grad)\n",
    "        grad = self.layer_hidden_1.backward(grad,lr)\n",
    "        # print('4:',grad.shape)\n",
    "        grad = self.NonLinear_1.backward(grad)\n",
    "        final_grad = self.layer_in.backward(grad,lr)\n",
    "\n",
    "        return loss,final_grad\n",
    "\n",
    "\n",
    "class Fully_Connect_Network2():\n",
    "    def __init__(self,  channel_settings):\n",
    "        self.layer_num = len(channel_settings)\n",
    "        self.channel_settings = channel_settings\n",
    "\n",
    "        self.linear_layers = []\n",
    "        self.nonlinear_layers = []\n",
    "\n",
    "        for (channel_in,channel_out) in channel_settings:\n",
    "            self.linear_layers.append(LinearLayer(channel_in,channel_out))\n",
    "            self.nonlinear_layers.append(Sigmoid())\n",
    "\n",
    "        self.loss = L2_loss()\n",
    "\n",
    "\n",
    "    def forward(self,X):\n",
    "\n",
    "        for i in range(self.layer_num):\n",
    "            X = self.linear_layers[i].forward(X)\n",
    "            X = self.nonlinear_layers[i].forward(X)\n",
    "        \n",
    "        return X\n",
    "\n",
    "\n",
    "    def backward(self,P,Y,lr):\n",
    "        \n",
    "        loss = self.loss.forward(P,Y)\n",
    "        grad = self.loss.backward(P,Y)\n",
    "        \n",
    "        for i in range(self.layer_num-1,-1,-1):\n",
    "            grad = self.nonlinear_layers[i].backward(grad)\n",
    "            grad = self.linear_layers[i].backward(grad,lr)\n",
    "\n",
    "        return loss, grad\n",
    "    \n",
    "\n",
    "    def save_weights(self,save_path='./FCN.npy'):\n",
    "        state_dict = []\n",
    "        for i in range(self.layer_num):\n",
    "            state_dict.append(self.channel_settings[i])\n",
    "            state_dict.append(self.linear_layers[i].W)\n",
    "        np.save(save_path,np.array(state_dict))\n",
    "\n",
    "\n",
    "    def load_weights(self,weights_file='./FCN.npy'):\n",
    "        state_dict = np.load(weights_file,allow_pickle=True)\n",
    "        for i in range(self.layer_num):\n",
    "            channel_setting = state_dict[2*i]\n",
    "            weights = state_dict[2*i+1]\n",
    "            if channel_setting == self.channel_settings[i]:\n",
    "                self.linear_layers[i].W = weights\n",
    "            else:\n",
    "                print('Weights no fit!!')\n",
    "    \n",
    "\n",
    "def normalize(dataset,mean,std):\n",
    "    dataset = (dataset - dataset.min()) / (dataset.max() - dataset.min()) # 0~1\n",
    "    return (dataset - mean)/std # -1~1\n",
    "\n",
    "def dataloader(images,labels,batchsize=4):\n",
    "    length,dim = images.shape\n",
    "    images = images[:(length//batchsize*batchsize)]\n",
    "    labels = labels[:(length//batchsize*batchsize)]\n",
    "    images = images[np.newaxis,:].reshape(-1,batchsize,dim)\n",
    "    labels = labels[np.newaxis,:].reshape(-1,batchsize,1)\n",
    "    return images,labels\n",
    "\n",
    "def train_epoch(model,images,labels,lr=1e-4,batchsize=4):\n",
    "\n",
    "    losses = []\n",
    "    grads = []\n",
    "    # print(dataset[:10])\n",
    "    images = normalize(images,0.5,0.5)\n",
    "    images,labels = dataloader(images,labels,batchsize=batchsize)\n",
    "    for image,label in zip(images,labels):\n",
    "        # print(i)\n",
    "        X = image.transpose(1,0)\n",
    "        Y = np.zeros((10,1))\n",
    "        Y[label] = 1\n",
    "        # forward\n",
    "        Pred = model.forward(X)\n",
    "        # backward\n",
    "        loss, final_grad = model.backward(Pred,Y,lr)\n",
    "        losses.append(loss)\n",
    "        grads.append(final_grad)\n",
    "        # print('label:',Y)\n",
    "        # if i%500 ==0:\n",
    "        #     tqdm.write(f'{i},pred:{Pred},label:{Y}')\n",
    "    return losses,grads\n",
    "\n",
    "# model = Fully_Connect_Network(784,10)\n",
    "model = Fully_Connect_Network2([(784,400),(400,200),(200,100),(100,10)])\n",
    "offsetx = 5\n",
    "offsety = -2\n",
    "lr = 0.001\n",
    "losses = []\n",
    "grads = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in tqdm(range(1000),ncols=10):\n",
    "batchsize = 4\n",
    "for epoch in tqdm(range(30),ncols=80):\n",
    "    loss, grad = train_epoch(model,images_train,labels_train,lr,batchsize)\n",
    "    losses.append(np.mean(loss))\n",
    "    grads.append(np.mean(grad))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = Fully_Connect_Network2([(784,400),(400,200),(200,100),(100,10)])\n",
    "model_trained.load_weights('./FCN.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Model eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15.0, 2.0)\n",
    "test = normalize(images_val,0.5,0.5)\n",
    "test_Num = 10\n",
    "idxs = np.random.randint(0,len(test),size=test_Num)\n",
    "predict_labels = []\n",
    "true_labels = []\n",
    "for i,idx in enumerate(idxs):\n",
    "    plt.subplot(1,test_Num,i+1)\n",
    "    # plt.axes('off')\n",
    "    image = test[idx]\n",
    "    label = labels_val[idx]\n",
    "    predict = model_trained.forward(image.reshape(784,1))\n",
    "    predict_lable = np.argmax(predict)\n",
    "    predict_labels.append(predict_lable)\n",
    "    true_labels.append(label)\n",
    "    plt.imshow(image.reshape(28,28))\n",
    "    plt.axis('off')\n",
    "\n",
    "judge = []\n",
    "for j in range(test_Num):\n",
    "    if true_labels[j] == predict_labels[j]:\n",
    "        judge.append('√')\n",
    "    else:\n",
    "        judge.append('❌')\n",
    "\n",
    "print(\"实际类别: \", \" | \".join(\"%7s\"%true_labels[j] for j in range(test_Num)))\n",
    "print(\"预测类别: \", \" | \".join(\"%7s\"%predict_labels[j] for j in range(test_Num)))\n",
    "print(\"--\"*56)\n",
    "print(\"判断正确？\", \" | \".join(\"%7s\"%judge[j] for j in range(test_Num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, F = 0,0\n",
    "test = normalize(images_val,0.5,0.5)\n",
    "\n",
    "for image,label in zip(test,labels_val):\n",
    "    predict = model_trained.forward(image.reshape(784,1))\n",
    "    P = np.argmax(predict)\n",
    "    if P == label: T+=1\n",
    "    else: F+=1\n",
    "\n",
    "print('average accuracy:',T/(T+F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Model testing with camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image0,thres=80):\n",
    "    image = cv2.cvtColor(image0,cv2.COLOR_RGB2GRAY)\n",
    "    image = cv2.resize(image,(28,28))\n",
    "    image_ = np.zeros_like(image) \n",
    "    image_[image<=thres]=1\n",
    "    image_[image>thres]=0\n",
    "    # image = (image - image.min())/(image.max() - image.min())\n",
    "    # image = 1-image\n",
    "    image = (image-0.5)/0.5\n",
    "\n",
    "    return image_\n",
    "\n",
    "def predict(model,frame):\n",
    "    img = preprocess(frame)\n",
    "    predict = model.forward(img.reshape(784,1))\n",
    "    return np.argmax(predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = Fully_Connect_Network2([(784,400),(400,200),(200,100),(100,10)])\n",
    "model_trained.load_weights('./FCN.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while(cap.isOpened()):\n",
    "    retval, frame = cap.read()\n",
    "    \n",
    "    label = predict(model_trained,frame)\n",
    "    AddText = frame.copy()\n",
    "    cv2.putText(AddText, str(label), (200, 100), cv2.FONT_HERSHEY_COMPLEX, 2.0, (100, 200, 200), 5)\n",
    "    res = np.hstack([frame, AddText])\n",
    "    \n",
    "    cv2.imshow('Live', res)\n",
    "\n",
    "    if cv2.waitKey(5) >= 0:\n",
    "        image = res\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "plt.imshow(image[:,:,::-1])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_process = preprocess(image)\n",
    "plt.imshow(image_process,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model_trained.forward(image_process.reshape(784,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict)\n",
    "np.argmax(predict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
